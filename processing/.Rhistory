if(THP<=0) break
}
if(THP>0){
return("Taran")
} else{
return("Giant")
}
}
replicate(10,turn())
TTurn = function(){
if ((sample(1:20,1)+5)>=13){
return(sample(1:8,1)+5)
}
else(return(0))
}
GTurn = function(){
out = 0
if((sample(1:20,1)+8)>=17){
out = out + 9
}
if((sample(1:20,1)+8)>=17){
out = out + 9
}
return(out)
}
turn = function(){
THP = 45
GHP = 105
while(T){
GHP = GHP - TTurn()
if(GHP<=0) break
THP = THP - GTurn()
if(THP<=0) break
}
if(THP>0){
return(c("Taran",THP))
} else{
return(c("Giant",GHP))
}
}
replicate(10,turn())
TTurn = function(){
if ((sample(1:20,1)+5)>=13){
return(sample(1:8,1)+5)
}
else(return(0))
}
GTurn = function(){
out = 0
if((sample(1:20,1)+8)>=17){
out = out + 9
}
if((sample(1:20,1)+8)>=17){
out = out + 9
}
return(out)
}
turn = function(){
THP = 90
GHP = 105
while(T){
GHP = GHP - TTurn()
if(GHP<=0) break
THP = THP - GTurn()
if(THP<=0) break
}
if(THP>0){
return(c("Taran",THP))
} else{
return(c("Giant",GHP))
}
}
replicate(10,turn())
replicate(TTurn())
replicate(10,TTurn())
replicate(10,GTurn())
TTurn = function(){
if ((sample(1:20,1)+5)>=13){
return(sample(1:8,1)+5)
}
else(return(0))
}
GTurn = function(){
out = 0
if((sample(1:20,1)+8)>=17){
out = out + 9
}
if((sample(1:20,1)+8)>=17){
out = out + 9
}
return(out)
}
turn = function(){
THP = 90
GHP = 105
while(T){
GHP = GHP - TTurn()
if(GHP<=0) break
THP = THP - GTurn()
if(THP<=0) break
}
if(THP>0){
return(c("Taran",THP))
} else{
return(c("Giant",GHP))
}
}
table(replicate(200,turn()))
TTurn = function(){
if ((sample(1:20,1)+5)>=13){
return(sample(1:8,1)+5)
}
else(return(0))
}
GTurn = function(){
out = 0
if((sample(1:20,1)+8)>=17){
out = out + 9
}
if((sample(1:20,1)+8)>=17){
out = out + 9
}
return(out)
}
turn = function(){
THP = 90
GHP = 105
while(T){
GHP = GHP - TTurn()
if(GHP<=0) break
THP = THP - GTurn()
if(THP<=0) break
}
if(THP>0){
return(c("Taran",THP))
} else{
return(c("Giant",GHP))
}
}
res = replicate(200,turn())
res
table(res[1,])
TTurn = function(){
if ((sample(1:20,1)+5)>=13){
return(sample(1:8,1)+5)
}
else(return(0))
}
GTurn = function(){
out = 0
if((sample(1:20,1)+8)>=17){
out = out + 9
}
#if((sample(1:20,1)+8)>=17){
#  out = out + 9
#}
return(out)
}
turn = function(){
THP = 90
GHP = 105
while(T){
GHP = GHP - TTurn()
if(GHP<=0) break
THP = THP - GTurn()
if(THP<=0) break
}
if(THP>0){
return(c("Taran",THP))
} else{
return(c("Giant",GHP))
}
}
res = replicate(200,turn())
table(res[1,])
TTurn = function(){
if ((sample(1:20,1)+5)>=13){
return(sample(1:8,1)+5)
}
else(return(0))
}
GTurn = function(){
out = 0
if((sample(1:20,1)+8)>=17){
out = out + 9
}
if((sample(1:20,1)+8)>=17){
out = out + 9
}
return(out)
}
turn = function(){
THP = 90
GHP = 50
while(T){
GHP = GHP - TTurn()
if(GHP<=0) break
THP = THP - GTurn()
if(THP<=0) break
}
if(THP>0){
return(c("Taran",THP))
} else{
return(c("Giant",GHP))
}
}
res = replicate(200,turn())
table(res[1,])
TTurn = function(){
if ((sample(1:20,1)+5)>=13){
return(sample(1:8,1)+5)
}
else(return(0))
}
GTurn = function(){
out = 0
if((sample(1:20,1)+8)>=17){
out = out + 9
}
if((sample(1:20,1)+8)>=17){
out = out + 9
}
return(out)
}
turn = function(){
THP = 90
GHP = 105
while(T){
GHP = GHP - TTurn()
if(GHP<=0) break
THP = THP - GTurn()
if(THP<=0) break
}
if(THP>0){
return(c("Taran",THP))
} else{
return(c("Giant",GHP))
}
}
res = replicate(200,turn())
table(res[1,])
hist(res[2,])
res[2,]
hist(as.numeric(res[2,]))
table(res[1,])
replicate(6,sample(1:9,1))
replicate(6,sample(1:9,1))
sample(sample(1:9,6))
sample(sample(1:9,10))
sample(sample(c(1:9,1:9),10))
sample(sample(c(1:9,1:9),10))
sample(sample(c(1:9,1:9),10))
x = sample(sample(c(1:9,1:9),10))
min(diff(x))
diff(x)
x
min(abs(diff(x)))
x = 1:2
while(min(abs(diff(x)))<=1){
x = sample(sample(c(1:9,1:9),10))
}
x
x = 1:2
while(min(abs(diff(x)))<=1){
x = sample(sample(c(1:9,1:9),10))
}
x
x = 1:2
while(min(abs(diff(x)))<=1){
x = sample(sample(c(1:9,1:9),10))
}
x
x = 1:2
while(min(abs(diff(x)))<=1){
x = sample(sample(c(1:9,1:9),11))
}
x
x = 1:2
while(min(abs(diff(x)))<=1){
x = sample(sample(c(1:9,1:9),11))
}
x
sample(x,4)
x = c( "sum", "hate", "harm", "wit", "bond",
"yield", "worst", "twice")
sample(x,4)
sample(x,4)
replicate(3,sample(x,4))
replicate(3,sample(x,5))
t(replicate(3,sample(x,5)))
t(replicate(3,sample(x,4)))
t(replicate(3,sample(x,4)))
x = c("association", "opportunity", "representative", "organization", "considerable", "immediately", "university", "individual")
x = c( "sum", "hate", "harm", "wit", "bond",
"yield", "worst", "twice")
t(replicate(3,sample(x,4)))
x = c( "sum", "hate", "harm", "wit", "bond",
"yield", "worst", "twice")
t(replicate(3,sample(x,4)))
x = c( "sum", "hate", "harm", "wit", "bond",
"yield", "worst", "twice")
t(replicate(3,sample(x,4)))
t(replicate(3,sample(x,5)))
t(replicate(3,sample(x,6)))
t(replicate(3,sample(x,7)))
t(replicate(3,sample(x,7)))
x = c("association", "opportunity", "representative", "organization", "considerable", "immediately", "university", "individual")
t(replicate(3,sample(x,4)))
t(replicate(3,sample(x,5)))
t(replicate(2,sample(x,6)))
t(replicate(2,sample(x,7)))
t(replicate(2,sample(x,7)))
t(replicate(2,sample(x,7)))
t(replicate(2,sample(x,7)))
t(replicate(2,sample(x,6)))
sample(0:31,1)==0
g = function(){
if(sample(0:31,1)==0){return("m")}
return(sample(c("m","f"),1))
}
table(replicate(1000,g()))
prop.table(table(replicate(1000,g())))
prop.table(table(replicate(10000,g())))
(1/31) + ((30/31)*0.5)
prop.table(table(replicate(100000,g())))
kk = c(49,75,62,44,82,68,58,68,82,60,66,49,49,54,69,52,51,49,54,49,69,64,65)
eb = c(61,69,68,55,70,67,51,56,68,64,40,64,74,68,61,60,66,40,38,58,59,67,65,60,40,63,13)
hist(kk)
hist(eb)
mean(kk)
mean(eb)
sort(kk)
mean(eb[eb>14])
sd(kk)
sd(eb[eb>14])
abline(h = 0, col = 'green')
View(d)
d = data.frame()
View(d)
BSA2018.final.datatables <- read.table("~/Downloads/BSA2018 final datatables.xlsx", header=TRUE, quote="\"")
View(BSA2018.final.datatables)
?mean
?sum
?nchar
nchar("Seán")
nchar("Seán", type="char")
nchar("Seán", type="bytes")
?mean
log(100)
log10(100)
?log
e
1.2e-4
10^3
1.2e3
server = read.delim("~/Downloads/tibetan_Server.txt",sep="\t",quote="",fileEncoding = "UTF-8",encoding = 'UTF-8', stringsAsFactors = F,comment.char = "#")
local = read.delim("../data/corrected/AllLangs_240_CogID_Sagart_Complete_Extended_Checked4.tsv",sep="\t",quote="",fileEncoding = "UTF-8",encoding = 'UTF-8',stringsAsFactors = F,comment.char = "#")
setwd("~/Documents/Funding/InternationalStrategicFund/project/analysis/")
local = read.delim("../data/corrected/AllLangs_240_CogID_Sagart_Complete_Extended_Checked4.tsv",sep="\t",quote="",fileEncoding = "UTF-8",encoding = 'UTF-8',stringsAsFactors = F,comment.char = "#")
table(local$CONCEPT,local$DOCULECT)
x =table(local$CONCEPT,local$DOCULECT)
table(serv)
setwd("~/Documents/Funding/InternationalStrategicFund/project/processing/")
d = read.csv("../data/corrected/AllLangs_240_CogID_Sagart_Complete_Extended_Checked4.tsv", sep="\t",comment.char = "#",encoding = "UTF-8",fileEncoding = "UTF-8",quote = "",stringsAsFactors = F)
################
# FINAL CHOICE #
################
outgroupLanguage = "S_Old_Chinese"
toIncludeFromSagart = c("S_Old_Tibetan","S_Tibetan_Batang","S_Tibetan_Xiahe","S_Tibetan_Lhasa","S_Tibetan_Alike",outgroupLanguage)
# Filter languages
d = d[(d$SOURCE=="") | (d$DOCULECT %in% toIncludeFromSagart),]
# Filter non-sorted cognates
d = d[d$COGID!=100000,]
# Filter concepts with no variation
cogsPerConcept = tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))})
conceptsWithNoVariation = names(cogsPerConcept)[cogsPerConcept==1]
d = d[!(d$CONCEPT %in% conceptsWithNoVariation),]
# Filter concepts that may be borrowings:
borrowings = c("TOMATO")
d = d[!d$CONCEPT %in% borrowings,]
# Filter concepts that are compounds (see Sagart SI page 15)
compounds = c("NOON","FIREWOOD")
d = d[!(d$CONCEPT %in% compounds),]
# Filter Concepts for which we only have data for our languages
sourcesPerConcept = tapply(d$SOURCE,d$CONCEPT,function(X){length(unique(X))})
conceptsWithOnlyOurData = names(sourcesPerConcept)[sourcesPerConcept==1]
# Concepts for our data with maximum variation
dx = d[d$CONCEPT %in% conceptsWithOnlyOurData,]
#sort(tapply(dx$COGID,dx$CONCEPT,function(X){length(unique(X))}))
keepMaxVarConcepts = c("GO","WHOLE","SPEAK","MORTAR CRUSHER","BREAD","RICE","COW")
conceptsWithOnlyOurData = conceptsWithOnlyOurData[!(conceptsWithOnlyOurData %in% keepMaxVarConcepts)]
d = d[!(d$CONCEPT %in% conceptsWithOnlyOurData),]
# Check concept coverage
# Sagart: "we made sure that all languages have translations for at least 85% of the concepts in our questionnaire"
numConceptsPerLang = sort(tapply(d$CONCEPT,d$DOCULECT,function(X){length(unique(X))}))
conceptCoverage = numConceptsPerLang/length(unique(d$CONCEPT))
conceptCoverage
all(conceptCoverage>=0.85)
conceptCoverage
setwd("~/Documents/Funding/InternationalStrategicFund/project/processing/")
d = read.csv("../data/corrected/AllLangs_240_CogID_Sagart_Complete_Extended_Checked4.tsv", sep="\t",comment.char = "#",encoding = "UTF-8",fileEncoding = "UTF-8",quote = "",stringsAsFactors = F)
################
# FINAL CHOICE #
################
outgroupLanguage = "S_Old_Chinese"
toIncludeFromSagart = c("S_Old_Tibetan","S_Tibetan_Batang","S_Tibetan_Xiahe","S_Tibetan_Lhasa","S_Tibetan_Alike",outgroupLanguage)
# Filter languages
d = d[(d$SOURCE=="") | (d$DOCULECT %in% toIncludeFromSagart),]
# Filter non-sorted cognates
d = d[d$COGID!=100000,]
# Filter concepts with no variation
cogsPerConcept = tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))})
conceptsWithNoVariation = names(cogsPerConcept)[cogsPerConcept==1]
d = d[!(d$CONCEPT %in% conceptsWithNoVariation),]
# Filter concepts that may be borrowings:
borrowings = c("TOMATO")
d = d[!d$CONCEPT %in% borrowings,]
# Filter concepts that are compounds (see Sagart SI page 15)
compounds = c("NOON","FIREWOOD")
d = d[!(d$CONCEPT %in% compounds),]
# Filter Concepts for which we only have data for our languages
sourcesPerConcept = tapply(d$SOURCE,d$CONCEPT,function(X){length(unique(X))})
conceptsWithOnlyOurData = names(sourcesPerConcept)[sourcesPerConcept==1]
# Concepts for our data with maximum variation
dx = d[d$CONCEPT %in% conceptsWithOnlyOurData,]
#sort(tapply(dx$COGID,dx$CONCEPT,function(X){length(unique(X))}))
keepMaxVarConcepts = c("GO","WHOLE","SPEAK","MORTAR CRUSHER","BREAD","RICE","COW")
conceptsWithOnlyOurData = conceptsWithOnlyOurData[!(conceptsWithOnlyOurData %in% keepMaxVarConcepts)]
d = d[!(d$CONCEPT %in% conceptsWithOnlyOurData),]
# Check concept coverage
# Sagart: "we made sure that all languages have translations for at least 85% of the concepts in our questionnaire"
numConceptsPerLang = sort(tapply(d$CONCEPT,d$DOCULECT,function(X){length(unique(X))}))
conceptCoverage = numConceptsPerLang/length(unique(d$CONCEPT))
conceptCoverage
all(conceptCoverage>=0.85)
# Check HORSE is still in data:
"HORSE" %in% d$CONCEPT
"PIG" %in% d$CONCEPT
"COW" %in% d$CONCEPT
"RICE" %in% d$CONCEPT
"BARLEY" %in% d$CONCEPT
"WHEAT" %in% d$CONCEPT
# Check cogids aren't shared across concepts
conceptsPerCognate = tapply(d$CONCEPT,d$COGID,function(X){length(unique(X))})
all(conceptsPerCognate==1)
########
# Stats
length(unique(d$CONCEPT))
length(unique(d$DOCULECT))
tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))})
hist(tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))}))
median(tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))}))
range(tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))}))
mean(tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))}))
setwd("~/Documents/Funding/InternationalStrategicFund/project/processing/")
d = read.csv("../data/corrected/AllLangs_240_CogID_Sagart_Complete_Extended_Checked4.tsv", sep="\t",comment.char = "#",encoding = "UTF-8",fileEncoding = "UTF-8",quote = "",stringsAsFactors = F)
################
# FINAL CHOICE #
################
outgroupLanguage = "S_Old_Chinese"
toIncludeFromSagart = c("S_Old_Tibetan","S_Tibetan_Batang","S_Tibetan_Xiahe","S_Tibetan_Lhasa","S_Tibetan_Alike",outgroupLanguage)
# Filter languages
d = d[(d$SOURCE=="") | (d$DOCULECT %in% toIncludeFromSagart),]
# Filter non-sorted cognates
d = d[d$COGID!=100000,]
# Filter concepts with no variation
cogsPerConcept = tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))})
conceptsWithNoVariation = names(cogsPerConcept)[cogsPerConcept==1]
d = d[!(d$CONCEPT %in% conceptsWithNoVariation),]
# Filter concepts that may be borrowings:
borrowings = c("TOMATO")
d = d[!d$CONCEPT %in% borrowings,]
# Filter concepts that are compounds (see Sagart SI page 15)
compounds = c("NOON","FIREWOOD")
d = d[!(d$CONCEPT %in% compounds),]
# Filter Concepts for which we only have data for our languages
sourcesPerConcept = tapply(d$SOURCE,d$CONCEPT,function(X){length(unique(X))})
conceptsWithOnlyOurData = names(sourcesPerConcept)[sourcesPerConcept==1]
# Concepts for our data with maximum variation
dx = d[d$CONCEPT %in% conceptsWithOnlyOurData,]
#sort(tapply(dx$COGID,dx$CONCEPT,function(X){length(unique(X))}))
keepMaxVarConcepts = c("GO","WHOLE","SPEAK","MORTAR CRUSHER","BREAD","RICE","COW")
conceptsWithOnlyOurData = conceptsWithOnlyOurData[!(conceptsWithOnlyOurData %in% keepMaxVarConcepts)]
d = d[!(d$CONCEPT %in% conceptsWithOnlyOurData),]
# Check concept coverage
# Sagart: "we made sure that all languages have translations for at least 85% of the concepts in our questionnaire"
numConceptsPerLang = sort(tapply(d$CONCEPT,d$DOCULECT,function(X){length(unique(X))}))
conceptCoverage = numConceptsPerLang/length(unique(d$CONCEPT))
conceptCoverage
all(conceptCoverage>=0.85)
# Check HORSE is still in data:
"HORSE" %in% d$CONCEPT
"PIG" %in% d$CONCEPT
"COW" %in% d$CONCEPT
"RICE" %in% d$CONCEPT
"BARLEY" %in% d$CONCEPT
"WHEAT" %in% d$CONCEPT
# Check cogids aren't shared across concepts
conceptsPerCognate = tapply(d$CONCEPT,d$COGID,function(X){length(unique(X))})
all(conceptsPerCognate==1)
########
# Stats
length(unique(d$CONCEPT))
length(unique(d$DOCULECT))
length(unique(paste(d$CONCEPT,d$COGID)))
range(tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))}))
mean(tapply(d$COGID,d$CONCEPT,function(X){length(unique(X))}))
# Number of cases where a language has more than one cognate set per concept
dim(d)
names(d)
write.table(d,"~/Downloads/FinalDataForPhylogeny", sep="\t",quote = F)
write.table(d,"~/Downloads/FinalDataForPhylogeny", sep="\t",quote = F,row.names = F)
